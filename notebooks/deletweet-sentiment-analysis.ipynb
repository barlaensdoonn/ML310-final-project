{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETWEET SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "import matplotlib\n",
    "import nltk.classify.util\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = [18.0, 12.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *TRAIN CLASSIFIER*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK provides a [HOW-TO](http://www.nltk.org/howto/twitter.html) which serves as a tutorial for using their built-in classes to interact with the Twitter API and gather a tweet corpus to use for text mining and natural language processing. They also provide their own Twitter corpus which consists of three separate texts: the first is a random collection of tweets gathered within a certain timeframe under certain search parameters. The other two are collections of 5,000 tweets each, classified as expressing positive and negative sentiment respectively.\n",
    "\n",
    "Interestingly the tweets were gathered and classed by searching for correlated text emojis. For example, tweets containing emojis such as :-), :), ;), :o), :] were classified as positive, while tweets containing emojis like :L, :<, :-(, >.< were classed as negative. The negative class has [in my opinion] more potentially neutral - or just non-negative - emojis than the positive class, such as :S, :@ and =/. This could lead to more neutral texts being classified as negative, which we will see happen later on.\n",
    "\n",
    "For training our Naive Bayes Classifier we used StreamHacker's [series of blog posts](http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/) as a guide. The interface to the classifier is provided by NLTK, as is the tokenized version of the tweet corpus. However, we normalized their provided tweet corpus by converting the tokenized text to lowercase before training, which greatly improved the relevance of the classifier's most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    '''\n",
    "    this function borrowed from: http://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/\n",
    "\n",
    "    \"All of the NLTK classifiers work with featstructs, which can be simple dictionaries\n",
    "    mapping a feature name to a feature value. For text, we’ll use a simplified\n",
    "    bag of words model where every word is feature name with a value of True.\"\n",
    "    '''\n",
    "\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out tokenized text from the classified tweets provided by NLTK\n",
    "# more info: http://www.nltk.org/howto/twitter.html#Using-a-Tweet-Corpus\n",
    "tokenized_negative = twitter_samples.tokenized('negative_tweets.json')\n",
    "tokenized_positive = twitter_samples.tokenized('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize text by transforming to lowercase\n",
    "negatives_normalized = [[word.lower() for word in thing] for thing in tokenized_negative]\n",
    "positives_normalized = [[word.lower() for word in thing] for thing in tokenized_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run through wordfeats() to convert into featstructs for NLTK classifier\n",
    "negatives = [(word_feats(negatives_normalized[i]), 'neg') for i in range(len(tokenized_negative))]\n",
    "positives = [(word_feats(positives_normalized[i]), 'pos') for i in range(len(tokenized_positive))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 7500 instances, test on 2500 instances\n"
     ]
    }
   ],
   "source": [
    "# split dataset into 75% train/25% test\n",
    "neg_split = int(len(negatives) * 0.75)\n",
    "pos_split = int(len(positives) * 0.75)\n",
    "train_feats = negatives[:neg_split] + positives[:pos_split]\n",
    "test_feats = negatives[neg_split:] + positives[pos_split:]\n",
    "print('train on {} instances, test on {} instances'.format(len(train_feats), len(test_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_feats)\n",
    "print('accuracy: {}'.format(nltk.classify.util.accuracy(classifier, test_feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      :( = True              neg : pos    =   2214.3 : 1.0\n",
      "                      :) = True              pos : neg    =   1073.8 : 1.0\n",
      "                    glad = True              pos : neg    =     25.7 : 1.0\n",
      "                     x15 = True              neg : pos    =     23.7 : 1.0\n",
      "                 arrived = True              pos : neg    =     21.8 : 1.0\n",
      "                     sad = True              neg : pos    =     21.2 : 1.0\n",
      "                    sick = True              neg : pos    =     19.7 : 1.0\n",
      "               community = True              pos : neg    =     15.7 : 1.0\n",
      "                   loves = True              pos : neg    =     14.1 : 1.0\n",
      "                     ugh = True              neg : pos    =     13.7 : 1.0\n",
      "                    miss = True              neg : pos    =     13.3 : 1.0\n",
      "              definitely = True              pos : neg    =     13.0 : 1.0\n",
      "                      aw = True              neg : pos    =     13.0 : 1.0\n",
      "                   shame = True              neg : pos    =     12.3 : 1.0\n",
      "                follback = True              pos : neg    =     12.3 : 1.0\n",
      "                   didnt = True              neg : pos    =     12.3 : 1.0\n",
      "              appreciate = True              pos : neg    =     11.7 : 1.0\n",
      "              bestfriend = True              pos : neg    =     11.0 : 1.0\n",
      "                   hurts = True              neg : pos    =     11.0 : 1.0\n",
      "           @justinbieber = True              neg : pos    =     10.6 : 1.0\n",
      "                   sorry = True              neg : pos    =     10.2 : 1.0\n",
      "               followers = True              pos : neg    =     10.2 : 1.0\n",
      "                       ( = True              neg : pos    =     10.2 : 1.0\n",
      "                   tired = True              neg : pos    =     10.1 : 1.0\n",
      "                    huhu = True              neg : pos    =      9.7 : 1.0\n",
      "               goodnight = True              pos : neg    =      9.7 : 1.0\n",
      "                   enjoy = True              pos : neg    =      9.4 : 1.0\n",
      "                     via = True              pos : neg    =      9.3 : 1.0\n",
      "                   thank = True              pos : neg    =      9.1 : 1.0\n",
      "           opportunities = True              pos : neg    =      9.0 : 1.0\n",
      "                   @uber = True              neg : pos    =      9.0 : 1.0\n",
      "                    cold = True              neg : pos    =      9.0 : 1.0\n",
      "           unfortunately = True              neg : pos    =      9.0 : 1.0\n",
      "                 welcome = True              pos : neg    =      9.0 : 1.0\n",
      "                      :( = None              pos : neg    =      8.7 : 1.0\n",
      "                   great = True              pos : neg    =      8.4 : 1.0\n",
      "                     thx = True              pos : neg    =      8.3 : 1.0\n",
      "                  invite = True              pos : neg    =      8.3 : 1.0\n",
      "                 sharing = True              pos : neg    =      7.8 : 1.0\n",
      "                  missed = True              neg : pos    =      7.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training we can see that the classifier's most informative features are indeed good indicators for text sentiment. Words such as loves, appreciate, enjoy, welcome, great, and thank are all correctly identified as expressing positive sentiment, while words such as sad, sick, ugh, hurts, and sorry are indicative of negative sentiment. The text emojis :) and :( are the strongest indicators of positive and negative sentiment respectively, which makes sense given how the tweets were chosen and classified initially. Interestingly the 2 twitter users @justinbieber and @uber are both associated with negative sentiment, which may be an indicator of popular public opinion of those two users at the time the tweets were gathered. These features also suggest that if our classifier extends poorly to tweets in the wild, we might need to do more preprocessing of the training set, such as removing special characters and twitter users. It is worth noting that the NLTK tweet tokenizer has an optional parameter that allows for the removal of twitter usernames from the text during tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *CLASSIFY DATASET*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use our trained Naive Bayes classifier to classify the Politwoops dataset of deleted tweets. Before classification we import the dataset and remove any remaining bad rows that pandas.read_csv() missed. Then we construct a list of strings separated by tweet to hold the text for tokenization. We use the tweet tokenizer provided by NLTK, which is designed for more casual text. This tokenizer allows us to convert the text to lowercase on tokenization with preserve_case=False. We then use the word_feats() function to construct a featstruct out of the tokenized text for the classifier, as we did with NLTK's corpus before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1157: expected 11 fields, saw 141\\nSkipping line 2263: expected 11 fields, saw 77\\nSkipping line 2319: expected 11 fields, saw 92\\nSkipping line 4631: expected 11 fields, saw 129\\nSkipping line 8260: expected 11 fields, saw 89\\nSkipping line 8823: expected 11 fields, saw 84\\nSkipping line 8824: expected 11 fields, saw 129\\nSkipping line 10197: expected 11 fields, saw 131\\nSkipping line 10278: expected 11 fields, saw 123\\nSkipping line 10297: expected 11 fields, saw 123\\nSkipping line 10311: expected 11 fields, saw 123\\nSkipping line 10401: expected 11 fields, saw 79\\nSkipping line 10430: expected 11 fields, saw 154\\nSkipping line 10495: expected 11 fields, saw 92\\nSkipping line 12989: expected 11 fields, saw 77\\nSkipping line 14473: expected 11 fields, saw 73\\nSkipping line 16741: expected 11 fields, saw 79\\nSkipping line 22015: expected 11 fields, saw 81\\nSkipping line 22322: expected 11 fields, saw 123\\nSkipping line 22957: expected 11 fields, saw 74\\nSkipping line 24728: expected 11 fields, saw 81\\nSkipping line 28474: expected 11 fields, saw 73\\nSkipping line 29656: expected 11 fields, saw 75\\nSkipping line 29834: expected 11 fields, saw 100\\nSkipping line 31272: expected 11 fields, saw 88\\nSkipping line 37306: expected 11 fields, saw 76\\nSkipping line 42274: expected 11 fields, saw 76\\nSkipping line 46399: expected 11 fields, saw 75\\nSkipping line 47628: expected 11 fields, saw 103\\nSkipping line 47803: expected 11 fields, saw 74\\nSkipping line 53572: expected 11 fields, saw 77\\nSkipping line 54441: expected 11 fields, saw 72\\nSkipping line 55591: expected 11 fields, saw 68\\nSkipping line 61022: expected 11 fields, saw 72\\nSkipping line 61023: expected 11 fields, saw 72\\nSkipping line 64356: expected 11 fields, saw 76\\nSkipping line 65590: expected 11 fields, saw 73\\n'\n",
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# import dataset and remove bad rows\n",
    "deletweet = pandas.read_csv('../data/deleted_tweets.csv', error_bad_lines=False)\n",
    "\n",
    "bad_rows = []\n",
    "\n",
    "for i in range(len(deletweet)):\n",
    "    if type(deletweet['tweet'][i]) != str:\n",
    "        bad_rows.append(i)\n",
    "    else:\n",
    "        tweet = json.loads(deletweet['tweet'][i])\n",
    "        if type(tweet) != dict:\n",
    "            bad_rows.append(i)\n",
    "\n",
    "deletweet.drop(deletweet.index[bad_rows], inplace=True)\n",
    "deletweet.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct a list of strings to hold the tweet text\n",
    "tweet_text_raw = []\n",
    "\n",
    "for i in range(len(deletweet)):\n",
    "    tweet = json.loads(deletweet['tweet'][i])\n",
    "    tweet_text_raw.append(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67756"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of individual tweets to classify\n",
    "len(tweet_text_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the tweet tokenizer provided by NLTK\n",
    "# preserve_case=False will transform all to lowercase\n",
    "tknzr = TweetTokenizer(preserve_case=False)\n",
    "tokenized = [tknzr.tokenize(tweet_text_raw[i]) for i in range(len(tweet_text_raw))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run tokenized lists through word_feats() to construct featstruct for NLTK classifier\n",
    "features = [word_feats(tokenized[i]) for i in range(len(tokenized))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classify!\n",
    "classed = classifier.classify_many(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classified_tweets = list(zip(classed, tweet_text_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *PLOT AND ANALYSIS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 30 tweets from the Politwoops dataset are printed out below, along with their classified sentiment. After reading through these and other subsets of the classified dataset we can see that the classifier performs fairly well, although not perfectly, as indicated by the very first tweet being misclassified as negative. There is definite room for improvement, and a more robust feature set for training would likely go a long way. Expanding on the original search by specifically gathering tweets of a political nature in association with positive and negative text emojis might go a long way in ameliorating the defiiciencies of the classifier. After more consideration, it seems that the biggest improvement would come from the addition of a third neutral class, since many of the tweets are ambiguous in sentiment, and therefore should not be classified as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg : This is so cool. This same sort of adaptive protocol is being used with shipping drones as well. https://t.co/pLuU2ljAmg\n",
      "pos : https://t.co/V7Rc07GrJU\n",
      "pos : #TBT @MikePenceVP https://t.co/tSZUjMjaaI\n",
      "pos : I had a cordial and candidate discussion today with the new DHS Secretary, John Kelly. https://t.co/4neFHS3Mji\n",
      "pos : Grt to host @USProgressives Specl Order w/@RepRaskin on #MuslimBan.Thx @RepMarkTakano @RepLawrence @RepGaramendi @RepCicilline @RepBarragan\n",
      "pos : I'm an original co-sponsor of @RepDonBeyer’s Freedom of Religon Act, protecting our values in response to @POTUS’ #MuslimBan. #FORAct\n",
      "neg : ⚡️ “Rieckhoff vs. Tester”\n",
      "\n",
      "https://t.co/JBr4v7j5PM\n",
      "pos : @IAVA CEO @PaulRieckhoff &amp; I are going #Head2Head to determine who dons the better ‘do. Post #Jon or #Paul to cast… https://t.co/GemjAHTZf7\n",
      "pos : @IAVA CEO @PaulRieckhoff &amp; I are going #Head2Head to determine who dons the better ‘do. Post #Jon or #Paul to cast your vote below!\n",
      "pos : @IAVA CEO @PaulReickhoff &amp; I are going #Head2Head to determine who dons the better ‘do. Reply with #Jon or #Paul to… https://t.co/D6JAMWIQVD\n",
      "pos : @IAVA CEO @PaulReickhoff and I are going #Head2Head to determine, once and for all, who dons the better ‘do. Cast y… https://t.co/IN8GU4Cf6i\n",
      "pos : @IAVA CEO @PaulReickhoff &amp; I are going #Head2Head to determine, once and for all, who dons the better ‘do. Cast you… https://t.co/XbDY4WicBO\n",
      "pos : .@HouseGOP have privately (&amp; rightfully) expressed fears about what #ACARepeal would mean for Americans. I thought… https://t.co/L29B3lPrAG\n",
      "pos : Not to worry. @realDonaldTrump promises to deliver a sensible, coherent plan for #MiddleEast peace on February 31. https://t.co/A3WYrOiIZY\n",
      "neg : Right now, Voting NO on going to Executive Session for nomination Price, Mnuchin and Sessions. No on Devos tomorrow morning.\n",
      "pos : These words take on new meaning in the #Trump Administration. https://t.co/TKHksDSGjn\n",
      "pos : .@HouseGOP have privately (&amp; rightfully) expressed fears about what #ACARepeal would mean for Americans. I thought… https://t.co/b9gwivlASJ\n",
      "pos : .@SenateMajLdr McConnell comments on measure --&gt; Video here: https://t.co/0yxGDq8cY6\n",
      "@WLKY https://t.co/WBq3aIm8Sc\n",
      "pos : .@SenateMajLdr McConnell comments on passage of anti-coal measure: https://t.co/K1ENddRMtH https://t.co/p9RkzurxDs\n",
      "pos : .@realDonaldTrump, FYI: Федеральная служба безопасности Российской Федерации =/= @CIA, @NSAGov, or @FBI.\n",
      "https://t.co/WkESVXnNA6\n",
      "neg : Tune into the now LIVE forum to hear from panelists, including Dr. Kahn about the #MuslimBan https://t.co/zqeyFkFppX https://t.co/suovuLy8Bg\n",
      "pos : JOBS: The AR1 will provide the US with a new, world-competitive engine for launch vehicles, 100 jobs for Alabamians. https://t.co/jRFqrUsNt8\n",
      "pos : We're working to ensure the hiring freeze does not prevent the @forestservice from preparing for wildfire season. https://t.co/RPOOEEzjsd\n",
      "pos : A new era of transparency begins at the @FCC  Thank you @AjitPaiFCC and @mikeoreilly https://t.co/ExPWdSKqhd\n",
      "pos : .@MichStatePolice still working hard to track down Officer Collin Rose’s killer, but they need your help… https://t.co/xHccCTuRS4\n",
      "pos : .@realDonaldTrump What's your stance on painkillers? Beta-endorphins invented at #UCBerkeley\n",
      "neg : Discrimination under the guise of \"religious freedom\" is still discrimination. I urge @POTUS not to reconsider.\n",
      "https://t.co/v2g9tOSzXP\n",
      "pos : @Fortunatebri I have no doubt. But I also know I can do a better job of jackasses currently in there - if you'll excuse my donkey mouth.\n",
      "pos : Great news from @AjiPaiFCC today – promise to make @FCC more open &amp; transparent, giving radio broadcasters more flexibility. #ProcessReform\n",
      "neg : RT @zenbeatnik: @Scotttaylorva But executed by Trump. The blaming of Obama must stop.\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print('{} : {}'.format(classified_tweets[i][0], classified_tweets[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# seperate the classification into positive and negative buckets\n",
    "pos_class = [thing for thing in classed if thing =='pos']\n",
    "neg_class = [thing for thing in classed if thing == 'neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive tweets: 51260\n",
      "negative tweets: 16496\n"
     ]
    }
   ],
   "source": [
    "split = [len(pos_class), len(neg_class)]\n",
    "print('positive tweets: {}'.format(split[0]))\n",
    "print('negative tweets: {}'.format(split[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_series = pandas.Series(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x135dfb080>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCQAAAK4CAYAAACs4iwLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAkAAABgnCABAAAAjBMkAAAAgHH/D75hGO6zTvi+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1359826a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_series.plot.bar(title='DELETED TWEETS BY SENTIMENT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 0 represents the positive class and 1 represents the negative class. There are over 50,000 positive tweets vs. roughly 16,000 negative tweets. This seems to make sense given the political context of the tweets: politicians are likely to use twitter to express positive sentiment about their actions or things they support, such as bills. This is perhaps unique to political tweets in that the regular population's tweets are likely to be more personal and quotidian in nature, and therefore may not be so heavily weighted toward the positive class. Also, as stated above, the addition of a neutral class would likely change this distribution significantly, although we would expect more positive classes to change to neutral in that case than negative to neutral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
